{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of firstname_lastname_p1.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6UHmLYVhWAN"
      },
      "source": [
        "# Project 1: Digit Classification with KNN and Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03M_JSg3hWAO"
      },
      "source": [
        "In this project, you'll implement your own image recognition system for classifying digits. Read through the code and the instructions carefully and add your own code where indicated. Each problem can be addressed succinctly with the included packages -- please don't add any more. Grading will be based on writing clean, commented code, along with a few short answers.\n",
        "\n",
        "As always, you're welcome to work on the project in groups and discuss ideas on the course wall, but <b> please prepare your own write-up (with your own code). </b>\n",
        "\n",
        "If you're interested, check out these links related to digit recognition:\n",
        "\n",
        "* Yann Lecun's MNIST benchmarks: http://yann.lecun.com/exdb/mnist/\n",
        "* Stanford Streetview research and data: http://ufldl.stanford.edu/housenumbers/\n",
        "\n",
        "Finally, if you'd like to get started with Tensorflow, you can read through this tutorial: https://www.tensorflow.org/tutorials/keras/basic_classification. It uses a dataset called \"fashion_mnist\", which is identical in structure to the original digit mnist, but uses images of clothing rather than images of digits. The number of training examples and number of labels is the same. In fact, you can simply replace the code that loads \"fashion_mnist\" with \"mnist\" and everything should work fine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJ9ayCvyhWAP"
      },
      "source": [
        "# This tells matplotlib not to try opening a new window for each plot.\n",
        "%matplotlib inline\n",
        "\n",
        "# Import a bunch of libraries.\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MultipleLocator\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix, r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from typing import * # Used so I can add PEP 484 type annotations\n",
        "\n",
        "# Set the randomizer seed so results are the same each time.\n",
        "np.random.seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAaoZbsaVb2_"
      },
      "source": [
        "import sklearn\n",
        "sklearn.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO1t0ypThWAR"
      },
      "source": [
        "Load the data. Notice that the data gets partitioned into training, development, and test sets. Also, a small subset of the training data called mini_train_data and mini_train_labels gets defined, which you should use in all the experiments below, unless otherwise noted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yK9DacchWAS"
      },
      "source": [
        "# Load the digit data from https://www.openml.org/d/554 or from default local location '~/scikit_learn_data/...'\n",
        "X, Y = fetch_openml(name='mnist_784', return_X_y=True, cache=False)\n",
        "\n",
        "\n",
        "# Rescale grayscale values to [0,1].\n",
        "X = X / 255.0\n",
        "\n",
        "# Shuffle the input: create a random permutation of the integers between 0 and the number of data points and apply this\n",
        "# permutation to X and Y.\n",
        "# NOTE: Each time you run this cell, you'll re-shuffle the data, resulting in a different ordering.\n",
        "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
        "X, Y = X[shuffle], Y[shuffle]\n",
        "\n",
        "print('data shape: ', X.shape)\n",
        "print('label shape:', Y.shape)\n",
        "\n",
        "# Set some variables to hold test, dev, and training data.\n",
        "test_data, test_labels = X[61000:], Y[61000:]\n",
        "dev_data, dev_labels = X[60000:61000], Y[60000:61000]\n",
        "train_data, train_labels = X[:60000], Y[:60000]\n",
        "mini_train_data, mini_train_labels = X[:1000], Y[:1000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atc2JpWKhWAV"
      },
      "source": [
        "### Part 1:\n",
        "\n",
        "Show a 10x10 grid that visualizes 10 examples of each digit.\n",
        "\n",
        "Notes:\n",
        "* You can use `plt.rc()` for setting the colormap, for example to black and white.\n",
        "* You can use `plt.subplot()` for creating subplots.\n",
        "* You can use `plt.imshow()` for rendering a matrix.\n",
        "* You can use `np.array.reshape()` for reshaping a 1D feature vector into a 2D matrix (for rendering)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "436UeH7JhWAW"
      },
      "source": [
        "#def P1(num_examples=10):\n",
        "\n",
        "### STUDENT START ###\n",
        "def P1(num_examples=10):\n",
        "  digits = {str(i): [] for i in range(10)}\n",
        "  remaining = [str(i) for i in range(10)]\n",
        "\n",
        "  # Separating digits into 0-9 labeled examples\n",
        "  for x, y in zip(X, Y):\n",
        "    if y in remaining:\n",
        "      digits[y].append(x)\n",
        "\n",
        "      if len(digits[y]) == num_examples:\n",
        "        remaining.remove(y)\n",
        "    \n",
        "    if len(remaining) == 0:\n",
        "      break\n",
        "  \n",
        "  # Drawing the samples\n",
        "  f = plt.figure()\n",
        "  f.set_figwidth(10)\n",
        "  f.set_figheight(10)\n",
        "  for d in range(10):\n",
        "    digit_samples = digits[str(d)]\n",
        "\n",
        "    # For each sample in the digit, draw it to a subplot\n",
        "    for i, sample in enumerate(digit_samples):\n",
        "      plt.subplot(10, num_examples, 10 * d + i + 1)\n",
        "      plt.imshow(sample.reshape(28, 28))\n",
        "      plt.axis('off')\n",
        "\n",
        "### STUDENT END ###\n",
        "\n",
        "P1(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMQAHr7QhWAX"
      },
      "source": [
        "### Part 2:\n",
        "\n",
        "Produce k-Nearest Neighbors models with k $\\in$ [1,3,5,7,9].  Evaluate and show the accuracy of each model. For the 1-Nearest Neighbor model, additionally show the precision, recall, and F1 for each label. Which digit is the most difficult for the 1-Nearest Neighbor model to recognize?\n",
        "\n",
        "Notes:\n",
        "* Train on the mini train set.\n",
        "* Evaluate performance on the dev set.\n",
        "* You can use `KNeighborsClassifier` to produce a k-nearest neighbor model.\n",
        "* You can use `classification_report` to get precision, recall, and F1 results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-it5pn8-hWAY"
      },
      "source": [
        "#def P2(k_values):\n",
        "\n",
        "### STUDENT START ###\n",
        "\n",
        "def P2(k_values: List[int]):\n",
        "  for k in k_values:\n",
        "    # First, train a classifier with the given K\n",
        "    knn_classifier = KNeighborsClassifier(k)\n",
        "    knn_classifier.fit(mini_train_data, mini_train_labels)\n",
        "\n",
        "    # If k == 1, show more detailed performance characteristics\n",
        "    if k == 1:\n",
        "      print('k: 1')\n",
        "      true_labels = dev_labels\n",
        "      pred_labels = knn_classifier.predict(dev_data)\n",
        "\n",
        "      print(classification_report(true_labels, pred_labels))\n",
        "    \n",
        "    # Otherwise, just find and print the accuracy\n",
        "    else:\n",
        "      print(f'k: {k}\\taccuracy: {knn_classifier.score(dev_data, dev_labels)}')\n",
        "    \n",
        "### STUDENT END ###\n",
        "\n",
        "k_values = [1, 3, 5, 7, 9]\n",
        "P2(k_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZc9gzn5hWAZ"
      },
      "source": [
        "ANSWER:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b6YEAzzhWAa"
      },
      "source": [
        "### Part 3:\n",
        "\n",
        "Produce 1-Nearest Neighbor models using training data of various sizes.  Evaluate and show the performance of each model.  Additionally, show the time needed to measure the performance of each model.\n",
        "\n",
        "Notes:\n",
        "* Train on subsets of the train set.  For each subset, take just the first part of the train set without re-ordering.\n",
        "* Evaluate on the dev set.\n",
        "* You can use `KNeighborsClassifier` to produce a k-nearest neighbor model.\n",
        "* You can use `time.time()` to measure elapsed time of operations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEpNzDEjhWAa"
      },
      "source": [
        "#def P3(train_sizes, accuracies):\n",
        "\n",
        "### STUDENT START ###\n",
        "\n",
        "def P3(train_sizes: List[int], accuracies: List[float]):\n",
        "  # For each training size, it trains a classifier and prints\n",
        "  # its performance\n",
        "  for train_size in train_sizes:\n",
        "    nn_classifier = KNeighborsClassifier(1)\n",
        "    nn_classifier.fit(train_data[:train_size], train_labels[:train_size])\n",
        "\n",
        "    print(f'Trained 1NN Classifier with {train_size} data points')\n",
        "    start = time.time()\n",
        "    predictions = nn_classifier.predict(dev_data)\n",
        "    print(f'Time needed to evaluate model: {time.time() - start} seconds')\n",
        "    print(classification_report(dev_labels, predictions))\n",
        "\n",
        "    correct = len([None for l, r in zip(predictions, dev_labels) if l == r])\n",
        "    accuracies.append(correct / len(dev_labels))\n",
        "    \n",
        "    print('\\n====\\n')\n",
        "\n",
        "### STUDENT END ###\n",
        "\n",
        "train_sizes = [100, 200, 400, 800, 1600, 3200, 6400, 12800, 25600]\n",
        "accuracies = []\n",
        "P3(train_sizes, accuracies)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B56lVsKNhWAc"
      },
      "source": [
        "### Part 4:\n",
        "\n",
        "Produce a linear regression model that predicts accuracy of a 1-Nearest Neighbor model given training set size. Show $R^2$ of the linear regression model.  Show the accuracies predicted for training set sizes 60000, 120000, and 1000000.  Show a lineplot of actual accuracies and predicted accuracies vs. training set size over the range of training set sizes in the training data.  What's wrong with using linear regression here?\n",
        "\n",
        "Apply a transformation to the predictor features and a transformation to the outcome that make the predictions more reasonable.  Show $R^2$ of the improved linear regression model.  Show the accuracies predicted for training set sizes 60000, 120000, and 1000000.  Show a lineplot of actual accuracies and predicted accuracies vs. training set size over the range of training set sizes in the training data - be sure to display accuracies and training set sizes in appropriate units.\n",
        "\n",
        "Notes:\n",
        "* Train the linear regression models on all of the (transformed) accuracies estimated in Problem 3.\n",
        "* Evaluate the linear regression models on all of the (transformed) accuracies estimated in Problem 3.\n",
        "* You can use `LinearRegression` to produce a linear regression model.\n",
        "* Remember that the sklearn `fit()` functions take an input matrix X and output vector Y. So, each input example in X is a vector, even if it contains only a single value.\n",
        "* Hint re: predictor feature transform: Accuracy increases with training set size logarithmically.\n",
        "* Hint re: outcome transform: When y is a number in range 0 to 1, then odds(y)=y/(1-y) is a number in range 0 to infinity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xE_qIJghWAc"
      },
      "source": [
        "# def P4():\n",
        "### STUDENT START ###\n",
        "\n",
        "def P4():\n",
        "  import math\n",
        "  # First, make a model with no input transformations.\n",
        "  accuracy_predictor = LinearRegression()\n",
        "  accuracy_predictor.fit([[size] for size in train_sizes], accuracies)\n",
        "\n",
        "  predicted_accuracies = accuracy_predictor.predict([[size] for size in train_sizes])\n",
        "\n",
        "  # Then, show its R² value\n",
        "  r_sq = r2_score(accuracies, predicted_accuracies)\n",
        "  print(f'R² score is {r_sq}')\n",
        "\n",
        "  for train_size in [60000, 120000, 1000000]:\n",
        "    print(f'Predicted accuracy for training size {train_size}: {accuracy_predictor.predict([[train_size]])[0]}')\n",
        "\n",
        "  # Drawing the plot...\n",
        "  f = plt.figure()\n",
        "  f.set_figwidth(10)\n",
        "  f.set_figheight(10)\n",
        "  plt.title('Nearest Neighbor Accuracy vs Training Set Size')\n",
        "  plt.ylabel('1NN Classifier Accuracy')\n",
        "  plt.xlabel('Training Size')\n",
        "\n",
        "  plt.plot(train_sizes, accuracies, label='NN Accuracy')\n",
        "  plt.plot(train_sizes, predicted_accuracies, label='Predicted Accuracy')\n",
        "  plt.legend()\n",
        "\n",
        "  # Next, train a model with log input, which has better performance\n",
        "  f = plt.figure()\n",
        "  f.set_figwidth(10)\n",
        "  f.set_figheight(10)\n",
        "  plt.title('Nearest Neighbor Accuracy vs Log Training Set Size')\n",
        "  plt.ylabel('1NN Classifier Accuracy')\n",
        "  plt.xlabel('Log of Training Size')\n",
        "\n",
        "  plt.plot(train_sizes, accuracies, label='NN Accuracy')\n",
        "  accuracy_predictor.fit([[math.log(size)] for size in train_sizes], accuracies)\n",
        "  predicted_accuracies = accuracy_predictor.predict([[math.log(size)] for size in train_sizes])\n",
        "  plt.plot(train_sizes, predicted_accuracies, label='Predicted Accuracy')\n",
        "  plt.legend()\n",
        "\n",
        "  # Showing the improved R² score\n",
        "  r_sq = r2_score(accuracies, predicted_accuracies)\n",
        "  print(f'Improved R² score is {r_sq}')\n",
        "\n",
        "### STUDENT END ###\n",
        "\n",
        "P4()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYYYL9cGhWAe"
      },
      "source": [
        "ANSWER:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geAQJjGRhWAe"
      },
      "source": [
        "### Part 5:\n",
        "\n",
        "Produce a 1-Nearest Neighbor model and show the confusion matrix. Which pair of digits does the model confuse most often? Show the images of these most often confused digits.\n",
        "\n",
        "Notes:\n",
        "- Train on the mini train set.\n",
        "- Evaluate performance on the dev set.\n",
        "- You can use `confusion_matrix()` to produce a confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq36xaQohWAf"
      },
      "source": [
        "#def P5():\n",
        "\n",
        "### STUDENT START ###\n",
        "\n",
        "def P5():\n",
        "  # Train a nearest neighbor classifier\n",
        "  nn_classifier = KNeighborsClassifier(1)\n",
        "  nn_classifier.fit(mini_train_data, mini_train_labels)\n",
        "\n",
        "  # Get its confusion matrix\n",
        "  cm = confusion_matrix(dev_labels, nn_classifier.predict(dev_data))\n",
        "\n",
        "  # Draw the confusion matrix to show its performance visually\n",
        "  plt.imshow(cm.reshape(10, 10))\n",
        "  plt.xticks(list(range(10)))\n",
        "  plt.yticks(list(range(10)))\n",
        "  plt.title('Nearest Neighbor Confusion Matrix')\n",
        "\n",
        "  # This next loop finds the most commonly confused digits\n",
        "  max_confusion = 0\n",
        "  mc_i = None\n",
        "  mc_j = None\n",
        "  for i in range(10):\n",
        "    for j in range(10):\n",
        "      if i == j:\n",
        "        continue\n",
        "      \n",
        "      confusion = cm[i][j]\n",
        "\n",
        "      if confusion > max_confusion:\n",
        "        max_confusion = confusion\n",
        "        mc_i = i\n",
        "        mc_j = j\n",
        "  \n",
        "  print(f'The most confused digits are {mc_i} and {mc_j}, at {max_confusion} confusions')\n",
        "\n",
        "  # This is just a helper function to find some sample digits with a given label\n",
        "  def find_examples(X, Y, label, num_examples):\n",
        "    examples = []\n",
        "    for x, y in zip(X, Y):\n",
        "      if y == label:\n",
        "        examples.append(x)\n",
        "\n",
        "        if len(examples) >= num_examples:\n",
        "          return examples\n",
        "\n",
        "  plt.figure()\n",
        "\n",
        "  # Show 5 samples of the first confused digit\n",
        "  num_examples = 5\n",
        "  for i, sample in enumerate(find_examples(dev_data, dev_labels, str(mc_i), num_examples)):\n",
        "    plt.subplot(2, num_examples, i + 1)\n",
        "    plt.imshow(sample.reshape(28, 28))\n",
        "    plt.axis('off')\n",
        "  # Show 5 samples of the other confused digit\n",
        "  for i, sample in enumerate(find_examples(dev_data, dev_labels, str(mc_j), num_examples)):\n",
        "    plt.subplot(2, num_examples, num_examples + i + 1)\n",
        "    plt.imshow(sample.reshape(28, 28))\n",
        "    plt.axis('off')\n",
        "  \n",
        "### STUDENT END ###\n",
        "\n",
        "P5()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zi27o1FpVb3D"
      },
      "source": [
        "ANSWER: The most confused digits are 4 and 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgqMKb-hhWAh"
      },
      "source": [
        "### Part 6:\n",
        "\n",
        "A common image processing technique is to smooth an image by blurring. The idea is that the value of a particular pixel is estimated as the weighted combination of the original value and the values around it. Typically, the blurring is Gaussian, i.e., the weight of a pixel's influence is determined by a Gaussian function over the distance to the relevant pixel.\n",
        "\n",
        "Implement a simplified Gaussian blur filter by just using the 8 neighboring pixels like this: the smoothed value of a pixel is a weighted combination of the original value and the 8 neighboring values.\n",
        "\n",
        "Pick a weight, then produce and evaluate four 1-Nearest Neighbor models by applying your blur filter in these ways:\n",
        "- Do not use the filter\n",
        "- Filter the training data but not the dev data\n",
        "- Filter the dev data but not the training data\n",
        "- Filter both training data and dev data\n",
        "\n",
        "Show the accuracies of the four models evaluated as described.  Try to pick a weight that makes one model's accuracy at least 0.9.\n",
        "\n",
        "Notes:\n",
        "* Train on the (filtered) mini train set.\n",
        "* Evaluate performance on the (filtered) dev set.\n",
        "* There are other Guassian blur filters available, for example in `scipy.ndimage.filters`. You are welcome to experiment with those, but you are likely to get the best results with the simplified version described above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSKHmHGshWAi"
      },
      "source": [
        "#def P6():\n",
        "    \n",
        "### STUDENT START ###\n",
        "\n",
        "def P6():\n",
        "  from numpy import ndarray\n",
        "  from scipy.ndimage.filters import gaussian_filter\n",
        "\n",
        "  # I've found that the harder the training set is, the better the classifier\n",
        "  # performs. I've designed this blur matrix to make '4' and '9' as hard to\n",
        "  # differentiate as possible, and that seemed to make the model perform best.\n",
        "  blur_matrix = ndarray((3, 3), buffer=np.array([\n",
        "    1.0, 1.0, 3.0,\n",
        "    2.0, 0.0, 2.0,\n",
        "    3.0, 1.0, 1.0\n",
        "  ]))\n",
        "\n",
        "  # Helper function to blur a single image\n",
        "  def blur(image, blur_matrix: ndarray):\n",
        "    # return gaussian_filter(image, sigma=1.3)\n",
        "\n",
        "    assert image.shape in [(784, ), (28, 28)] # Only supporting these shapes\n",
        "    assert blur_matrix.shape == (3, 3)\n",
        "    image = image.reshape(28, 28)\n",
        "    # This is simpler than having 2 delta i/j loops\n",
        "    deltas = [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 0), (0, 1), (1, -1), (1, 0), (1, 1)]\n",
        "    # Turns the gaussian matrix into a simple array of weights\n",
        "    weights = blur_matrix.reshape((9,))\n",
        "\n",
        "    result = ndarray((28, 28), buffer=np.zeros((28, 28)))\n",
        "\n",
        "    # For each pixel in the result, generate it with a weighted average of its neighbors\n",
        "    for i in range(1, 27):\n",
        "      for j in range(1, 27):\n",
        "        inputs = [image[i + di, j + dj] for di, dj in deltas]\n",
        "\n",
        "        result[i, j] = np.average(inputs, weights=weights)\n",
        "    \n",
        "    return result.reshape((784,))\n",
        "\n",
        "  # Helper function to blur an entire dataset\n",
        "  def blur_dataset(data):\n",
        "    return [blur(d, blur_matrix) for d in data]\n",
        "\n",
        "  # This just demonstrates one normal and blurred image\n",
        "  plt.imshow(X[1].reshape(28, 28))\n",
        "  plt.axis('off')\n",
        "  plt.figure()\n",
        "  plt.imshow(blur(X[1].reshape(28, 28), blur_matrix).reshape(28, 28))\n",
        "  plt.axis('off')\n",
        "\n",
        "  # Blurs the mini training / test sets\n",
        "  start = time.time()\n",
        "  print('Blurring dev...')\n",
        "  blurred_dev = blur_dataset(dev_data)\n",
        "  print(f'Done blurring dev in {time.time() - start} sec')\n",
        "\n",
        "  start = time.time()\n",
        "  print('Blurring training...')\n",
        "  blurred_train = blur_dataset(mini_train_data)\n",
        "  print(f'Done blurring training in {time.time() - start} sec')\n",
        "\n",
        "  print(time.time() - start)\n",
        "\n",
        "  # Trains both unblurred and blurred classifiers\n",
        "  unblurred_cls = KNeighborsClassifier(1)\n",
        "  unblurred_cls.fit(mini_train_data, mini_train_labels)\n",
        "\n",
        "  blurred_cls = KNeighborsClassifier(1)\n",
        "  blurred_cls.fit(blurred_train, mini_train_labels)\n",
        "\n",
        "  # Shows performance for [classifiers] x [datasets]\n",
        "  print(f'Unblurred classifier, Unblurred dataset: {unblurred_cls.score(dev_data, dev_labels)}')\n",
        "  print(f'Unblurred classifier,   Blurred dataset: {unblurred_cls.score(blurred_dev, dev_labels)}')\n",
        "  print(f'  Blurred classifier, Unblurred dataset: {blurred_cls.score(dev_data, dev_labels)}')\n",
        "  print(f'  Blurred classifier,   Blurred dataset: {blurred_cls.score(blurred_dev, dev_labels)}')\n",
        "\n",
        "### STUDENT END ###\n",
        "\n",
        "P6()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtgepWfAhWAk"
      },
      "source": [
        "### Part 7:\n",
        "\n",
        "Produce two Naive Bayes models and evaluate their performances.  Recall that Naive Bayes estimates P(feature|label), where each label is a categorical, not a real number.\n",
        "\n",
        "For the first model, map pixel values to either 0 or 1, representing white or black - you should pre-process the data or use `BernoulliNB`'s `binarize` parameter to set the white/black separation threshold to 0.1.  Use `BernoulliNB` to produce the model.\n",
        "\n",
        "For the second model, map pixel values to either 0, 1, or 2, representing white, gray, or black - you should pre-process the data, seting the white/gray/black separation thresholds to 0.1 and 0.9.  Use `MultinomialNB` to produce the model. \n",
        "\n",
        "Show the Bernoulli model accuracy and the Multinomial model accuracy.\n",
        "\n",
        "Notes:\n",
        "* Train on the mini train set.\n",
        "* Evaluate performance on the dev set.\n",
        "* `sklearn`'s Naive Bayes methods can handle real numbers, but for this exercise explicitly do the mapping to categoricals. \n",
        "\n",
        "Does the multinomial version improve the results? Why or why not?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGpH-4IQhWAk"
      },
      "source": [
        "#def P7():\n",
        "\n",
        "### STUDENT START ###\n",
        "\n",
        "def P7():\n",
        "  # Helper function to quantize given images\n",
        "  def discretize(vector):\n",
        "    nda = np.ndarray((784,))\n",
        "\n",
        "    for i, v in enumerate(vector):\n",
        "      nda[i] = 0 if v < 0.1 else 1 if v < 0.9 else 2\n",
        "    \n",
        "    return nda\n",
        "  \n",
        "  # Helper function to quantize an entire dataset\n",
        "  def discretize_dataset(vectors):\n",
        "    return [discretize(v) for v in vectors]\n",
        "\n",
        "  # Trains and tests a Bernoulli classifier\n",
        "  nbn = BernoulliNB(binarize=0.1)\n",
        "  nbn.fit(mini_train_data, mini_train_labels)\n",
        "\n",
        "  print(f'Binary NB score: {nbn.score(dev_data, dev_labels)}')\n",
        "\n",
        "  # Trains and tests a Multinomial classifier with quantized input\n",
        "  mbn = MultinomialNB()\n",
        "  discretized_train = discretize_dataset(mini_train_data)\n",
        "  mbn.fit(discretized_train, mini_train_labels)\n",
        "\n",
        "  print(f'Multinomial NB score: {mbn.score(discretize_dataset(dev_data), dev_labels)}')\n",
        "    \n",
        "### STUDENT END ###\n",
        "\n",
        "P7()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNLrgggohWAm"
      },
      "source": [
        "ANSWER:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqjbRLg7hWAm"
      },
      "source": [
        "### Part 8:\n",
        "\n",
        "Search across several values of the LaPlace smoothing parameter (alpha) to find its effect on a Bernoulli Naive Bayes model's performance.  Show the accuracy at each alpha value.\n",
        "\n",
        "Notes:\n",
        "* Set binarization threshold to 0.\n",
        "* Train on the mini train set.\n",
        "* Evaluate performance by 5-fold cross-validation. \n",
        "* Use `GridSearchCV(..., ..., cv=..., scoring='accuracy', iid=False)` to vary alpha and evaluate performance by cross-validation.\n",
        "* Cross-validation is based on partitions of the training data, so results will be a bit different than if you had used the dev set to evaluate performance.\n",
        "\n",
        "What is the best value for alpha? What is the accuracy when alpha is near 0? Is this what you'd expect?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AvZ-Wp3hWAn"
      },
      "source": [
        "#def P8(alphas):\n",
        "\n",
        "### STUDENT START ###\n",
        "\n",
        "def P8(alphas):\n",
        "  bnb = BernoulliNB(binarize=0.0)\n",
        "\n",
        "  # This for loop isn't required but shows the effect of alpha on performance\n",
        "  for alpha in [1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]:\n",
        "    nbnb = BernoulliNB(binarize=0.0, alpha=alpha)\n",
        "    nbnb.fit(mini_train_data, mini_train_labels)\n",
        "    print(f'alpha: {alpha}\\tscore: {nbnb.score(dev_data, dev_labels)}')\n",
        "\n",
        "  # Create the required validator and fit it\n",
        "  x_validator = GridSearchCV(bnb, alphas, cv=5, scoring='accuracy', iid=False)\n",
        "  x_validator.fit(mini_train_data, mini_train_labels)\n",
        "\n",
        "  return x_validator\n",
        "\n",
        "### STUDENT END ###\n",
        "\n",
        "alphas = {'alpha': [1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]}\n",
        "nb = P8(alphas)\n",
        "print()\n",
        "print(\"Best alpha = \", nb.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yEg9keThWAp"
      },
      "source": [
        "ANSWER:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B07GDiDdhWAq"
      },
      "source": [
        "### Part 9:\n",
        "\n",
        "Produce a model using Guassian Naive Bayes, which is intended for real-valued features, and evaluate performance. You will notice that it does not work so well. Diagnose the problem and apply a simple fix so that the model accuracy is around the same as for a Bernoulli Naive Bayes model. Show the model accuracy before your fix and the model accuracy after your fix.  Explain your solution.\n",
        "\n",
        "Notes:\n",
        "* Train on the mini train set.\n",
        "* Evaluate performance on the dev set.\n",
        "* Consider the effects of theta and sigma.  These are stored in the model's `theta_` and `sigma_` attributes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBLbTMWChWAq"
      },
      "source": [
        "#def P9():\n",
        "\n",
        "### STUDENT END ###\n",
        "\n",
        "def P9():\n",
        "  # Poorly performing Gaussian NB classifier\n",
        "  gnb = GaussianNB()\n",
        "  gnb.fit(mini_train_data, mini_train_labels)\n",
        "\n",
        "  print(f'With no tuning, Gaussian NB scores {gnb.score(dev_data, dev_labels)}')\n",
        "\n",
        "  # Improved Gaussian NB classifier, with a variance smoothing determined by trial-and-error\n",
        "  gnb = GaussianNB(var_smoothing=0.06765)\n",
        "  gnb.fit(mini_train_data, mini_train_labels)\n",
        "\n",
        "  print(f'After tuning var_smoothing, Gaussian NB scores {gnb.score(dev_data, dev_labels)}')\n",
        "\n",
        "### STUDENT END ###\n",
        "\n",
        "P9()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SyHTEJohWAt"
      },
      "source": [
        "ANSWER:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgZMuc1VhWAt"
      },
      "source": [
        "### Part 10:\n",
        "\n",
        "Because Naive Bayes produces a generative model, you can use it to generate digit images.\n",
        "\n",
        "Produce a Bernoulli Naive Bayes model and then use it to generate a 10x20 grid with 20 example images of each digit. Each pixel output should be either 0 or 1, based on comparing some randomly generated number to the estimated probability of the pixel being either 0 or 1.  Show the grid.\n",
        "\n",
        "Notes:\n",
        "* You can use np.random.rand() to generate random numbers from a uniform distribution.\n",
        "* The estimated probability of each pixel being 0 or 1 is stored in the model's `feature_log_prob_` attribute. You can use `np.exp()` to convert a log probability back to a probability.\n",
        "\n",
        "How do the generated digit images compare to the training digit images?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktii-Mp-hWAu"
      },
      "source": [
        "#def P10(num_examples):\n",
        "\n",
        "### STUDENT START ###\n",
        "\n",
        "def P10(num_examples: int):\n",
        "  bnb = BernoulliNB(binarize=0.1)\n",
        "  bnb.fit(mini_train_data, mini_train_labels)\n",
        "\n",
        "  # Because I wanted to show various generated images, I made this\n",
        "  # helper function take a section argument, which is a function that\n",
        "  # maps probabilities to pixel values.\n",
        "  def generate_image(feature_log_prob, pix_mapper):\n",
        "    nda = np.ndarray((784,))\n",
        "\n",
        "    for i, log_prob in enumerate(feature_log_prob):\n",
        "      p = np.exp(log_prob)\n",
        "      # nda[i] = 1 if np.random.rand() < p else 0\n",
        "      nda[i] = pix_mapper(p)\n",
        "    \n",
        "    return nda\n",
        "\n",
        "  # The weighted random pixel map for the problem\n",
        "  def weighted_random(p):\n",
        "    return 1 if np.random.rand() < p else 0\n",
        "\n",
        "  # Showing a quantized \"ground truth\"\n",
        "  def quantize(p):\n",
        "    return 1 if p > 0.5 else 0\n",
        "\n",
        "  # Showing the raw \"ground truth\"\n",
        "  def noop(p):\n",
        "    return p\n",
        "\n",
        "  log_features = bnb.feature_log_prob_\n",
        "\n",
        "  print('Showing the Bernoulli \"ground truth\", both as the raw probability and quantized')\n",
        "\n",
        "  # First demonstrating the pixel stats the classifier found\n",
        "  f = plt.figure()\n",
        "  f.set_figwidth(10)\n",
        "  f.set_figheight(4)\n",
        "  for i in range(10):\n",
        "    plt.subplot(2, 5, 1 + i)\n",
        "    plt.imshow(generate_image(log_features[i], noop).reshape(28, 28))\n",
        "    plt.axis('off')\n",
        "  f = plt.figure()\n",
        "  f.set_figwidth(10)\n",
        "  f.set_figheight(4)\n",
        "  for i in range(10):\n",
        "    plt.subplot(2, 5, 1 + i)\n",
        "    plt.imshow(generate_image(log_features[i], quantize).reshape(28, 28))\n",
        "    plt.axis('off')\n",
        "\n",
        "  f = plt.figure()\n",
        "  f.set_figwidth(20)\n",
        "  f.set_figheight(10)\n",
        "\n",
        "  # Now, drawing 20 randomly generated, noisy samples of each digit\n",
        "  for i in range(10):\n",
        "    for j in range(num_examples):\n",
        "      plt.subplot(10, 20, 1 + 20 * i + j)\n",
        "      plt.imshow(generate_image(log_features[i], weighted_random).reshape(28, 28))\n",
        "      plt.axis('off')\n",
        "\n",
        "### STUDENT END ###\n",
        "\n",
        "P10(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuQd1fTGhWAw"
      },
      "source": [
        "ANSWER:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksHMg73uhWAx"
      },
      "source": [
        "### Part 11:\n",
        "\n",
        "Recall that a strongly calibrated classifier is rougly 90% accurate when the posterior probability of the predicted class is 0.9. A weakly calibrated classifier is more accurate when the posterior probability of the predicted class is 90% than when it is 80%. A poorly calibrated classifier has no positive correlation between posterior probability and accuracy.  \n",
        "\n",
        "Produce a Bernoulli Naive Bayes model.  Evaluate performance: partition the dev set into several buckets based on the posterior probabilities of the predicted classes - think of a bin in a histogram- and then estimate the accuracy for each bucket. So, for each prediction, find the bucket to which the maximum posterior probability belongs, and update \"correct\" and \"total\" counters accordingly.  Show the accuracy for each bucket.\n",
        "\n",
        "Notes:\n",
        "* Set LaPlace smoothing (alpha) to the optimal value (from part 8).\n",
        "* Set binarization threshold to 0.\n",
        "* Train on the mini train set.\n",
        "* Evaluate perfromance on the dev set.\n",
        "\n",
        "How would you characterize the calibration for this Bernoulli Naive Bayes model?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1N-St12hWAy"
      },
      "source": [
        "#def P11(buckets, correct, total):\n",
        "    \n",
        "### STUDENT START ###\n",
        "\n",
        "def P11(buckets, correct, total):\n",
        "  # First, pick the best alpha found earlier\n",
        "  alpha = nb.best_params_['alpha']\n",
        "  print(f'Using alpha = {alpha}')\n",
        "\n",
        "  # Now, train a classifier with that hyperparameter\n",
        "  bnb = BernoulliNB(alpha=alpha, binarize=0)\n",
        "  bnb.fit(mini_train_data, mini_train_labels)\n",
        "\n",
        "  # Helper function to sort max probabilities into buckets\n",
        "  def find_bucket(prob):\n",
        "    for i, upper in enumerate(buckets):\n",
        "      if upper >= prob:\n",
        "        return i\n",
        "\n",
        "  # For each item in the test set, find its confidence bucket and count it\n",
        "  for probs, y in zip(bnb.predict_proba(dev_data), dev_labels):\n",
        "    max_prob = max(probs)\n",
        "    bucket = find_bucket(max_prob)\n",
        "    pred_y = str(list(probs).index(max_prob))\n",
        "\n",
        "    total[bucket] += 1\n",
        "\n",
        "    if pred_y == y:\n",
        "      correct[bucket] += 1\n",
        "\n",
        "### STUDENT END ###\n",
        "\n",
        "buckets = [0.5, 0.9, 0.999, 0.99999, 0.9999999, 0.999999999, 0.99999999999, 0.9999999999999, 1.0]\n",
        "correct = [0 for i in buckets]\n",
        "total = [0 for i in buckets]\n",
        "\n",
        "P11(buckets, correct, total)\n",
        "\n",
        "for i in range(len(buckets)):\n",
        "    accuracy = 0.0\n",
        "    if (total[i] > 0): accuracy = correct[i] / total[i]\n",
        "    print('p(pred) is %.13f to %.13f    total = %3d    accuracy = %.3f' % (0 if i==0 else buckets[i-1], buckets[i], total[i], accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-4qQsrrhWA1"
      },
      "source": [
        "ANSWER:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLDISyh4hWA1"
      },
      "source": [
        "### Part 12 EXTRA CREDIT:\n",
        "\n",
        "Design new features to see if you can produce a Bernoulli Naive Bayes model with better performance.  Show the accuracy of a model based on the original features and the accuracy of the model based on the new features.\n",
        "\n",
        "Here are a few ideas to get you started:\n",
        "- Try summing or averaging the pixel values in each row.\n",
        "- Try summing or averaging the pixel values in each column.\n",
        "- Try summing or averaging the pixel values in each square block. (pick various block sizes)\n",
        "- Try counting the number of enclosed regions. (8 usually has 2 enclosed regions, 9 usually has 1, and 7 usually has 0)\n",
        "\n",
        "Notes:\n",
        "* Train on the mini train set (enhanced to comprise the new features).\n",
        "* Evaulate performance on the dev set.\n",
        "* Ensure that your code is well commented."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-P7h-t2ThWA2"
      },
      "source": [
        "#def P12():\n",
        "\n",
        "### STUDENT START ###\n",
        "\n",
        "\n",
        "### STUDENT END ###\n",
        "\n",
        "#P12()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}